#!/usr/bin/python
from __future__ import print_function
import io, shutil
import csv
import numpy as np
from os import makedirs, path, sep
from optparse import OptionParser
from config import ModulesManager
from const import CSV_DIR, INI_DIR, DEFAULTS_ININAME, MEASUREMENTS_ININAME, \
    PROTO_DIR, PLOTSTYLE_ININAME
from shared import get_directories
from collections import namedtuple, defaultdict
from modules.shared.measurements import MEASUREMENTS_NAMES

MODMAN = ModulesManager()

BASE_MODULE = MODMAN.find_module('base', submodule='csv_parse')

# dynamicall created options: options added to generated MEASUREMENTS_ININAME
# file, that are not specified by the csv file
# {opt_name: gen_data_function} with 'gen_data_function(exp_type, data, modman)'
DYNAMIC_OPTIONS = {'measurements_length': None}

def parse_input():

    usage_str = (
         '\n\t %prog csv_ID'
         '\n\nwhere'
         '\n   csv_ID:'
         '\n       ID of the csv file to be processed. It will search for the '
         '.csv files in the CSV directory: \n       "' + CSV_DIR + '"'
         '\n       Inside has to be either file named csv_ID.csv (with .csv '
         'extension) or directory named \n       csv_ID containing file '
         'csv_ID.csv.'
         '\n\n       Example: '
         '\n           To process file named "experiment.csv" in the CSV '
         'directory (or in a subdirectory '
         '\n           named "experiment" inside the CSV directory), the '
         'command is:'
        '\n\t\t./mkini experiment')

    optparser = OptionParser(usage=usage_str)
    optparser.add_option('-l', '--list', dest='list', action="store_true",
                         default=False,
                         help="Lists all available CSV IDs")

    (options, args) = optparser.parse_args()

    len_args = len(args)

    if len_args == 0:
        if options.list:
            from os import listdir

            print('\nAvailable CSV IDs:\n--------------------')
            for csv_id in sorted(listdir(CSV_DIR)):
                if (len(csv_id) > 4) and (csv_id[-4:] == '.csv'):
                    print(csv_id[:-4])
                else:
                    print(csv_id)
            print()
        else:
            optparser.print_help()
        exit(0)

    csv_path = CSV_DIR + sep + args[0]

    if path.isdir(csv_path):
        csv_path        += sep
        csv_filebasename = args[0]
    else:
        csv_path         = CSV_DIR + sep
        csv_filebasename = args[0]

    if path.exists(csv_path + csv_filebasename):
        options.csv_filebasename = csv_filebasename[:-4] # truncate the extension
    elif path.exists(csv_path + csv_filebasename + '.csv'):
        options.csv_filebasename = csv_filebasename
    else:
        print('CSV file does not exist:{}'.format(csv_filebasename))
        exit(1)

    options.csv_path = csv_path

    if not path.exists(INI_DIR):
        makedirs(INI_DIR)

    return options

def get_module_function(function_name, module, base_module=BASE_MODULE):
    if hasattr(module, function_name):
        function = getattr(module, function_name)
    else:
        function = getattr(base_module, function_name)

    return function

def compress_seq(seq):
    if not type(seq) in [list, tuple]: return seq

    ref = seq[0]

    # all(seq[:] == ref)
    if not list(filter(lambda value: not (value == ref), seq)):
        return ref

    # all are == '' except one
    nonempty = list(filter(lambda value: not (value == ''), seq))
    items_count = len(nonempty)
    if items_count == 1:
        return nonempty[0]
    elif items_count == len(seq):
        return seq
    else:
        raise ValueError('Either all values in sequence must be nonempty, '
                         'or exactly one:\n', seq)

############################################################
#          Storage class for data read from CSV file       #
############################################################
class ExperimentData():
    def __init__(self, data_type, initial_data={}):
        self._data_type = data_type
        self._data = defaultdict(list, initial_data)

    def get_value(self, key, not_found=None):
        if not key in self._data:
            return not_found
        else:
            return self._data[key]

    def set_value(self, key, value):
        self._data[key] = value

    def append_row(self, row):
        data = self._data

        for (key, value) in vars(row).items():
            data[key].append(value)

    def iterate(self, fn, user_data=None):
        if user_data is None:
            for (key, value) in self._data.items(): fn(key, value)
        else:
            for (key, value) in self._data.items(): fn(key, value, user_data)

    def delete(self, *keys):
        data = self._data
        for key in keys: del data[key]

    def on_modify(self, fn):
        """
        Set the value returned by function fn as new value. If new_value is
        'None', then the key is deleted. Type of fn: fn(key, value)->new_value
        """

        delete_items = []

        experiment_data = self._data

        for (key, value) in experiment_data.items():
            new_value = fn(key, value)
            if new_value is None: delete_items.append(key)
            else: experiment_data[key] = new_value

        self.delete(*delete_items)

    def save(self, save_dir, filename=DEFAULTS_ININAME,
             section_name='experiment'):

        def _princ(key, value, stream):
            if value and type(value) in (list, tuple):
                value_str = '[' + str(value[0])
                for item in value[1:]:
                    value_str += ', ' + str(item)
                value_str += ']'
            else:
                value_str = value

            stream.write('{:8} = {}\n'.format(key, value_str))

        if callable(save_dir):
            savedir = save_dir(self)
        else:
            savedir = save_dir

        if not path.exists(savedir):
            makedirs(savedir)

        try:
            fout = open(savedir + filename, mode='w', encoding='utf-8')
        except:
            fout = open(savedir + filename, mode='w')
        fout.write('[{}]\n'.format(section_name))

        self.iterate(_princ, user_data=fout)

        fout.close()

    def echo(self):
        print()
        for (name, value) in sorted(self._data.items()):
            print('%-12s = %s' % (name, value))

    def get_datatype(self):
        return self._data_type

class MultipleExperimentData():
    def __init__(self, data_type):
        self._data_type = data_type
        self._data = {}

    def pick(self):
        leaf = self._data

        while not isinstance(leaf, ExperimentData):
            leaf = leaf.keys()[0]

        return leaf

    def _get_leaf(self, ids, create_p=False, not_found=None):
        data          = self._data
        parental_data = None

        for identifier in ids:
            if not identifier in data:
                if create_p:
                    data[identifier] = {}
                else:
                    return not_found
            parental_data = data
            data = data[identifier]

        if data == {}:
            data = ExperimentData(self._data_type)
            parental_data[ids[-1]] = data

        return data

    def get_value(self, key, not_found=None, *ids):
        leaf = self._get_leaf(ids, not_found=EOFError)
        if leaf == EOFError:
            return not_found
        else:
            return leaf.get_value(key)

    def set_value(self, key, value, *ids):
        leaf = self._get_leaf(ids, create_p=True)
        leaf.set_value(key, value)

    def append_row(self, row, *ids):
        leaf = self._get_leaf(ids, create_p=True)
        leaf.append_row(row)

    def iterate(self, fn, user_data=None, level_prehook=None,
                level_posthook=None, levels_names=None):

        def _traverse(struct, level):
            if isinstance(struct, ExperimentData):
                if user_data is None:
                    fn(struct)
                else:
                    fn(struct, user_data)
            else:
                for (key, value) in struct.items():
                    if not level_prehook is None:
                        if levels_names:
                            if not user_data is None:
                                level_prehook(levels_names[level], key,
                                              user_data)
                            else:
                                level_prehook(levels_names[level], key)

                        else:
                            level_prehook(key, user_data)

                    _traverse(value, level+1)

                    if not level_posthook is None:
                        if levels_names:
                            if not user_data is None:
                                level_posthook(levels_names[level], key,
                                               user_data)
                            else:
                                level_posthook(levels_names[level], key)

                        else:
                            level_posthook(key, user_data)

        _traverse(self._data, 0)

    def delete(self, *keys):
        def _delete_on_leafs(experiment):
            experiment.delete(*keys)

        self.iterate(_delete_on_leafs)

    def on_modify(self, fn):
        def _modify_leafs(experiment):
            experiment.on_modify(fn)

        self.iterate(_modify_leafs)

    def save(self, save_dir, filename=DEFAULTS_ININAME,
             section_name='experiment'):

        def _save_configuration(experiment):
            experiment.save(save_dir, filename, section_name)

        self.iterate(_save_configuration, verbose=False)

    def get_datatype(self):
        return self._data_type

############################################################
#                      Read CSV file(s)                    #
############################################################
def missing_fields_in_csv(csv_fields, fields):

    missing = list(filter(lambda field: not (field in csv_fields),
                          fields))
    return missing

def quote_string(string):
    tmp_str = string.strip()
    if len(tmp_str) > 1:
        if ((tmp_str[0] == tmp_str[-1] == '"')
            or (tmp_str[0] == tmp_str[-1] == "'")):
            pass
        else:
            tmp_str = "'" + tmp_str + "'"
    else:
        tmp_str = "'" + tmp_str + "'"

    return tmp_str

def quote_csv_file_string(key, value):

    if (key == 'csv_file') and (not value is None):
        new_value = []

        for csv_file_name in value:
            new_value.append(quote_string(csv_file_name))

        return new_value
    else:
        return value

def CSV2data(csv_dir, csv_filebasename):
    print('\t\t\tReading CSV file', csv_filebasename, '... ', end="")


    csv_filename = csv_dir + csv_filebasename + '.csv'
    # open CSV file
    try:
        f_csv = io.open(csv_filename, encoding='utf-8')
        csv_data = csv.reader(f_csv)
        csv_fields = next(csv_data)
    except UnicodeDecodeError:
        f_csv.close()

        try:
            f_csv = io.open(csv_filename, encoding='utf-16')
            csv_data = csv.reader(f_csv, delimiter=';')
            csv_fields = next(csv_data)
        except Exception:
            f_csv.close()

            print('\n\tCould not read CSV file:', csv_filebasename + '.csv',
                  'Unknown type of CSV file. Exiting...')
            exit(1)

    # determine CSV type
    if ((len(csv_fields) >= 2) and (csv_fields[0] == 'Name:')
        and (len(csv_fields[1]) >= 10) and (csv_fields[1][:10] == 'Data Instr')):

        try:
            #csv_fields = next(csv_data)
            while csv_fields[0] != 'Scan':
                csv_fields = next(csv_data) # skip useless header
        except Exception as msg:
            f_csv.close()

            print('Error during file reading occured. Message', msg, 'Exiting...')
            exit(1)

        # replace original column names with something more readable:
        # csv_fields = ('scan', 'time', 'elapsed', 's101', 's102', 's103', ...)
        for i in range(0, 3):
            csv_fields[i] = csv_fields[i].lower()
        for i in range(3, len(csv_fields)):
            fields = csv_fields[i].split(' ')
            csv_fields[i] = 's' + fields[0]

        csv_type = 'scanned_data'
        data = ExperimentData(csv_type)
    else:
        csv_type = 'regular_ini'
        required_fields = ('exp_type', 'exp_id', 'exp_no')
        missing = missing_fields_in_csv(csv_fields, required_fields)
        if not missing == []:
            print()
            print("CSV file: missing identifiers: '%s' "% missing)
            print('CSV error: cannot process CSV file, aborting...')
            exit(1)

        extended_fields = ('scan', 'csv_file', 'omega')
        missing = missing_fields_in_csv(csv_fields, extended_fields)
        if not missing:
            csv_type = 'scan_ini'
        elif not 'scan' in missing:
            print("ERROR: 'scan' value is provided in CSV file, but needed "
                  "identifiers are missing: ",  missing)
            print('CSV error: cannot process CSV file, aborting...')
            exit(1)

        identifiers = {}

        data = MultipleExperimentData(csv_type)

    csv_row = namedtuple('CSVRow', csv_fields)

    try:
        for row in map(csv_row._make, csv_data):
            if csv_type in ('regular_ini', 'scan_ini'):
                module = MODMAN.find_module(row.exp_type, submodule='csv_parse')
                skip   = get_module_function('skip', module)

                if skip(row): continue

                for id_name in ('exp_type', 'exp_id', 'exp_no'):
                    value = getattr(row, id_name)
                    if value:
                         identifiers[id_name] = value # update if value present

                (exp_id, exp_no) = (identifiers['exp_id'], identifiers['exp_no'])
                data.append_row(row, exp_id, exp_no)
            else:
                data.append_row(row)
    except Exception as msg:
        f_csv.close()

        print('Error during file reading occured, msg=\n', msg, ' Exiting...')
        exit(1)

    if csv_type == 'scanned_data':
        for name in csv_fields:
            if name in ('s102', 's103'):
                # force to use '.' as a delimiter for floats (and not ',')
                dval = []
                for value in data.get_value(name):
                    dval.append(value.replace(',', '.'))

                data.set_value(name, dval)
            else:
                # remove useless columns from data structure
                data.delete(name)

    if csv_type == 'scan_ini':
        # if needed, add quotes to values in csv_file field
        data.on_modify(quote_csv_file_string)

    return data

############################################################
#          Transform data and save to .ini file            #
############################################################
ITERABLE_LISTS = {}

def multiply_list(lst, coef):
    return [str(float(value) * coef) for value in lst]

def get_iterables_list(exp_type, modman):

    def extend_iterables_list(module):
        if hasattr(module, 'OPTIONS_ITERABLE_LISTS'):
            iterables_list.extend(module.OPTIONS_ITERABLE_LISTS)
        return True

    if exp_type in ITERABLE_LISTS:
        iterables_list = ITERABLE_LISTS[exp_type]
    else:
        iterables_list = []

        modman.traverse_ancestors(exp_type, extend_iterables_list,
                                  submodule='options')

        ITERABLE_LISTS[exp_type] = iterables_list

    return iterables_list

CSV2INI_NAMES = {'s102': 'gf_mt', 's103': 'gf_mo'}

def process_scanned_data(experiment, experiment_info):
    csv_files = experiment.get_value('csv_file')
    if not csv_files or csv_files in ["''", '""']:
        return

    data_dir  = get_directories('ini', 'data', experiment_info)

    if type(csv_files) == str:
        csv_scanned = csv_files.strip()
        if ((csv_scanned[0] == csv_scanned[-1] == '"')
            or (csv_scanned[0] == csv_scanned[-1] == "'")):
            csv_scanned = csv_scanned[1:-1]
        scanned_data = CSV2data(experiment_info['csv_path'], csv_scanned)
    else:
        raise ValueError('CSV file describing scanned data can contain '
                         'only one filename: ', csv_files)
    omegas = experiment.get_value('omega')
    scans  = np.asarray(experiment.get_value('scan'), dtype=int)
    (scan_first, scan_last) = (scans[0], scans[-1])

    scanned_inflow_weights  = scanned_data.get_value('s102')

    total_time = len(scanned_inflow_weights)
    # we assume measurement to be taken every second
    measurements_times = list(range(1, total_time+1))

    if not omegas:
        print('Rotational speed ''omega'' not specified: ', omegas,
              '\nExiting...')
        exit(1)

    c_omega = compress_seq(omegas)
    if type(c_omega) in (list, tuple): # mixed acc+dec+g
        omegas = np.asarray(omegas, dtype=float)

        include_acceleration = True

        omega_cen  = []
        a_duration = []
        d_duration = []
        g_duration = []

        omega = omegas[0]
        scan  = scans[0]

        if omega == 0.0:
            a_duration.append(0.0)

        append_g_duration = False

        scans_nr = len(scans)

        for i in range(1, scans_nr):
            omega_next = omegas[i]
            scan_next  = scans[i]

            # handle case last two omegas are same - the last value is needed
            if (omega == omega_next) and (i+1 < scans_nr): continue

            if omega > 0.0: # centrifugation
                omega_cen.append(omega)

                if omega < omega_next:
                    a_duration.append(scan_next - scan)
                    d_duration.append(0.0)
                    g_duration.append(0.0)
                elif omega_next == 0.0:
                    d_scan = scan_next - 15 # "guess" that dec takes at most 10s
                    mi0 = float(scanned_inflow_weights[d_scan])
                    for (sc, mi) in zip(range(d_scan+1, scan_next),
                                        scanned_inflow_weights[(d_scan+1):scan_next]):
                        mi = float(mi)
                        if abs(mi - mi0) < 0.5: # rough estimage of change
                            mi0 = mi # normal centrifugation; continue
                        else: # deceleration was triggered
                            d_scan = sc
                            break
                    a_duration.append(d_scan - scan)
                    d_duration.append(scan_next - d_scan)
                    append_g_duration = True # activate
                elif omega == omega_next:
                    if not i+1 == scans_nr:
                        raise ValueError('Something went wrong. omega can''t '
                                         'be equal to omega_next unless they '
                                         'are last values.')
                    print('\nWARNING: Last provided omega ' + str(omega) + 'is the '
                          'same as the previous one, hence no deceleration at '
                          'the end is performed !')
                    a_duration.append(scan_next - scan)
                    d_duration.append(0.0)
                    g_duration.append(0.0)
                else: # 0 < omega_next < omega
                    raise NotImplementedError('Decelerating to omega>0 is not '
                                              'supported.')
            else: # omega = 0.0 i.e. only g
                g_duration.append(scan_next - scan)
                append_g_duration = False # disable
                # a_duration, d_duration were set in previous iteration

            if append_g_duration:
                # was activated but not deactivated, so one final is missing
                g_duration.append(0.0)

            omega = omega_next
            scan  = scan_next

        a_duration_compressed = compress_seq(a_duration)
        d_duration_compressed = compress_seq(d_duration)
        g_duration_compressed = compress_seq(g_duration)


        if a_duration_compressed == 0.0: a_duration = 0.0
        if d_duration_compressed == 0.0: d_duration = 0.0
        if g_duration_compressed == 0.0: g_duration = 0.0

    else: # constant omega
        omega = c_omega
        if c_omega == 0.0:
            include_acceleration = False
            a_duration = 0.0
            d_duration = 0.0
            g_duration = total_time
        else:
            include_acceleration = True
            a_duration = total_time
            d_duration = 0.0
            g_duration = 0.0

    experiment.set_value('omega', omega_cen)
    experiment.set_value('include_acceleration', include_acceleration)
    experiment.set_value('duration', a_duration)
    experiment.set_value('deceleration_duration', d_duration)
    experiment.set_value('fh_duration', g_duration)

    # Truncate unused values
    for (csv_name, ini_name) in CSV2INI_NAMES.items():
        scanned_force_weights = scanned_data.get_value(csv_name)
        scanned_force_weights = \
          multiply_list(scanned_force_weights, 1000.) # kg -> g
        scanned_data.set_value(ini_name,
                               scanned_force_weights[scan_first: (scan_last+1)])
        scanned_data.delete(csv_name)

    filename = csv_scanned + '.ini'
    scanned_data.save(data_dir, filename)

PROCESS_DATA = {'regular_ini': lambda exp, info: True,
                'scan_ini': process_scanned_data}

def data2ini(data, experiment_info):

    def _get_measurement_length(key, value, array_info):
        if ((not type(value) in [list, tuple])
            or ((not key in array_info['iterables'])
                and (not key in array_info['measurements_names']))):
            return

        if array_info['len'] == -1:
            array_info['len'] = len(value)
            array_info['ref'] = key
        elif array_info['len'] != len(value):
            print("Option list '{}' has length: {:d}\n"
                  "Reference list '{}' has length: {:d}\n:"
                  "Cannot iterate over lists of unequal length. "
                  "Aborting.".format(key, len(value),
                                     array_info['ref'], array_info['len']))
            exit(1)

    def _filter_data(key, value):
        cvalue = compress_seq(value)

        # durations need to be handled specially
        if key in ('duration', 'fh_duration', 'deceleration_duration'):
            if ((not type(cvalue) in (list, tuple))
                and float(cvalue) == 0.0):

                return 0.0
            else: return value

        if cvalue in [None, '']: return None
        else: return cvalue

    def _pre_process_data(lname, lvalue, experiment_info):
        if lname == 'exp_id':
            print("\tProcessing experiment(s) with ID: ", repr(lvalue))
        else:
            print("\t\tProcessing experiment number: ", lvalue)

    def _post_process_data(lname, lvalue, experiment_info):

        if lname == 'exp_id':
            print("\tCreating default inifile for ID ",
                  repr(experiment_info['exp_id']), end = '')

            exp_base_path = get_directories('ini', 'exp_base', experiment_info)

            if path.exists(exp_base_path + DEFAULTS_ININAME):
                print('\n\t\tFile exists.\t\t\t\t\tSkipping'
                      .format(DEFAULTS_ININAME))

            else:
                default_configuration = \
                  ExperimentData('defaults',
                                 {'exp_type': repr(experiment_info['exp_type'])})

                default_configuration.save(exp_base_path,
                                           filename=DEFAULTS_ININAME,
                                           section_name='experiment')

            if not path.exists(exp_base_path + PLOTSTYLE_ININAME):
                shutil.copy(PROTO_DIR + PLOTSTYLE_ININAME + '.proto',
                            exp_base_path + PLOTSTYLE_ININAME)

            experiment_info['exp_type'] = None # reset exp_id for _process_data

            print()

    def _process_data(experiment, experiment_info):
        # Process single configuration file
        experiment.on_modify(_filter_data) # 'None' value returned from
                                           # _filter_data() is deleted

        exp_type = experiment.get_value('exp_type')
        if type(exp_type) in (list, tuple):
            print("Experiment type 'exp_type' must be the "
                  "same for given experiment. Exiting...")
            exit(1)

        if experiment_info['exp_type'] is None:
             experiment_info['exp_type'] = exp_type
        elif experiment_info['exp_type'] != exp_type:
            print("Experiment type 'exp_type' must be the same "
                      "for all experiments with given 'exp_id'.")
            exit(1)

        experiment_info['exp_id'] = experiment.get_value('exp_id')
        experiment_info['exp_no'] = experiment.get_value('exp_no')

        (data_dir, masks_dir)  = \
          get_directories('ini', ['data', 'masks'], experiment_info)

        if not path.exists(masks_dir):
            makedirs(masks_dir) # create empty masks directory

        # determine the size of iterable items (has to be the same for all)
        array_info = {'len': -1, 'ref': None,
                      'iterables': get_iterables_list(exp_type, MODMAN),
                      'measurements_names': MEASUREMENTS_NAMES.values()}

        experiment.iterate(_get_measurement_length, user_data=array_info)
        experiment.set_value('measurements_length', max(array_info['len'], 1))

        # support custom modification per-data_type
        PROCESS_DATA[experiment.get_datatype()](experiment, experiment_info)

        experiment.delete('exp_id', 'exp_no', 'exp_type')

        experiment.save(data_dir, filename=MEASUREMENTS_ININAME,
                        section_name='experiment-data')

        print('\t\t\tDone')

    print('\nCreating data inifiles...')
    experiment_info.update(dict.fromkeys(('exp_id', 'exp_no', 'mask',
                                          'exp_type')))
    data.iterate(_process_data, user_data=experiment_info,
                 levels_names=('exp_id', 'exp_no'),
                 level_prehook=_pre_process_data,
                 level_posthook=_post_process_data)
    print('All done.')

if __name__ == "__main__":
    options = parse_input()
    info = {'csv_path': options.csv_path,
            'csv_filebasename': options.csv_filebasename}

    data = CSV2data(info['csv_path'], info['csv_filebasename'])
    data2ini(data, info)
