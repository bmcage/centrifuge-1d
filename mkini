#!/usr/bin/python
import csv

from os import makedirs, path, sep
from optparse import OptionParser
from config import ModulesManager
from const import CSV_DIR, INI_DIR, DEFAULTS_ININAME, MEASUREMENTS_NAMES
from shared import get_directories
from collections import namedtuple, defaultdict

MODMAN = ModulesManager()

BASE_MODULE = MODMAN.find_module('base', submodule='csv_parse')

# dynamicall created options: options added to generated measurements.ini
# file, that are not specified by the csv file
# {opt_name: gen_data_function} with 'gen_data_function(exp_type, data, modman)'
DYNAMIC_OPTIONS = {'measurements_length': None}

def parse_input():

    usage_str = (
         '\n\t%prog <csv_ID>'
         '\n\nwhere'
         '\n  csv_ID:'
         '\n        ID of the csv file. By default will be searched for '
         '\n        the file ''./sources/csv/<csv_ID>[.cvs]'' ')

    optparser = OptionParser(usage=usage_str)
    optparser.add_option('-l', '--list', dest='list', action="store_true",
                         default=False,
                         help="Lists all available CSV files")

    (options, args) = optparser.parse_args()

    len_args = len(args)

    if len_args == 0:
        if options.list:
            from os import listdir

            print('\n'.join(sorted(listdir(CSV_DIR))))
        else:
            optparser.print_help()
        exit(0)

    csv_path = CSV_DIR + sep + args[0]

    if path.isdir(csv_path):
        csv_filepath = csv_path + sep
        csv_filename = args[0] + '.csv'
    else:
        csv_filepath = CSV_DIR + sep
        csv_filename = args[0]

    if path.exists(csv_filepaht + csv_filename):
        options.csv_filename = csv_filename
    elif path.exists(csv_filename + '.csv'):
        options.csv_filename = csv_filename + '.csv'
    else:
        print('CSV file does not exist:{}'.format(csv_filename))
        exit(1)
    options.csv_filepath = csv_filepath

    if not path.exists(INI_DIR):
        makedirs(INI_DIR)

    return options

def get_module_function(function_name, module, base_module=BASE_MODULE):
    if hasattr(module, function_name):
        function = getattr(module, function_name)
    else:
        function = getattr(base_module, function_name)

    return function

def compress_seq(seq):
    if not type(seq) in [list, tuple]: return seq

    ref = seq[0]

    # all(seq[:] == ref)
    if not list(filter(lambda value: not (value == ref), seq)):
        return ref

    # all are == '' except one
    nonempty = list(filter(lambda value: not (value == ''), seq))
    items_count = len(nonempty)
    if items_count == 1:
        return nonempty[0]
    elif items_count == len(seq):
        return seq
    else:
        raise ValueError('Either all values in sequence must be nonempty, '
                         'or exactly one:\n', seq)

############################################################
#          Storage class for data read from CSV file       #
############################################################
class ExperimentData():
    def __init__(self, data_type, initial_data={}):
        self._data_type = data_type
        self._data = defaultdict(list, initial_data)

    def get_value(self, key, not_found=None):
        if not key in self._data:
            return not_found
        else:
            return self._data[key]

    def set_value(self, key, value):
        self._data[key] = value

    def append_row(self, row):
        data = self._data

        for (key, value) in vars(row).items():
            data[key].append(value)

    def iterate(self, fn, user_data=None):
        if user_data is None:
            for (key, value) in self._data.items(): fn(key, value)
        else:
            for (key, value) in self._data.items(): fn(key, value, user_data)

    def delete(self, *keys):
        data = self._data
        for key in keys: del data[key]

    def on_modify(self, fn):
        """
        Set the value returned by function fn as new value. If new_value is
        'None', then the key is deleted. Type of fn: fn(key, value)->new_value
        """

        delete_items = []

        experiment_data = self._data

        for (key, value) in experiment_data.items():
            new_value = fn(key, value)
            if new_value is None: delete_items.append(key)
            else: experiment_data[key] = new_value

        self.delete(*delete_items)

    def save(self, save_dir, filename=DEFAULTS_ININAME,
             section_name='experiment'):

        def _princ(key, value, stream):
            if type(value) in (list, tuple):
                value_str = '[' + (', '.join(value)) +  ']'
            else:
                value_str = value

            stream.write('{:8} = {}\n'.format(key, value_str))

        if callable(save_dir):
            savedir = save_dir(self)
        else:
            savedir = save_dir

        if not path.exists(savedir):
            makedirs(savedir)

        fout = open(savedir + filename, mode='w', encoding='utf-8')
        fout.write('[{}]\n'.format(section_name))

        self.iterate(_princ, user_data=fout)

        fout.close()

    def echo(self):
        print()
        for (name, value) in sorted(self._data.items()):
            print('%-12s = %s' % (name, value))

    def get_datatype(self):
        return self._data_type

class MultipleExperimentData():
    def __init__(self, data_type):
        self._data_type = data_type
        self._data = {}

    def pick(self):
        leaf = self._data

        while not isinstance(leaf, ExperimentData):
            leaf = leaf.keys()[0]

        return leaf

    def _get_leaf(self, ids, create_p=False, not_found=None):
        data          = self._data
        parental_data = None

        for identifier in ids:
            if not identifier in data:
                if create_p:
                    data[identifier] = {}
                else:
                    return not_found
            parental_data = data
            data = data[identifier]

        if data == {}:
            data = ExperimentData(self._data_type)
            print('ids', ids)
            parental_data[ids[-1]] = data
            #FFF print('\nDDD', data, ids)
        return data

    def get_value(self, key, not_found=None, *ids):
        leaf = self._get_leaf(ids, not_found=EOFError)
        if leaf == EOFError:
            return not_found
        else:
            return leaf.get_value(key)

    def set_value(self, key, value, *ids):
        leaf = self._get_leaf(ids, create_p=True)
        leaf.set_value(key, value)

    def append_row(self, row, *ids):
        leaf = self._get_leaf(ids, create_p=True)
        #FFF print('\nLeaf', leaf)
        leaf.append_row(row)

    def iterate(self, fn, user_data=None, level_prehook=None,
                level_posthook=None, levels_names=None):

        def _traverse(struct, level):
            if isinstance(struct, ExperimentData):
                if user_data is None:
                    fn(struct)
                else:
                    fn(struct, user_data)
            else:
                for (key, value) in struct.items():
                    if not level_prehook is None:
                        if levels_names:
                            if not user_data is None:
                                level_prehook(levels_names[level], key,
                                              user_data)
                            else:
                                level_prehook(levels_names[level], key)

                        else:
                            level_prehook(key, user_data)

                    _traverse(value, level+1)

                    if not level_posthook is None:
                        if levels_names:
                            if not user_data is None:
                                level_posthook(levels_names[level], key,
                                               user_data)
                            else:
                                level_posthook(levels_names[level], key)

                        else:
                            level_posthook(key, user_data)

        _traverse(self._data, 0)

    def delete(self, *keys):
        def _delete_on_leafs(experiment):
            experiment.delete(*keys)

        self.iterate(_delete_on_leafs)

    def on_modify(self, fn):
        def _modify_leafs(experiment):
            experiment.on_modify(fn)

        self.iterate(_modify_leafs)

    def save(self, save_dir, filename=DEFAULTS_ININAME,
             section_name='experiment'):

        def _save_configuration(experiment):
            experiment.save(save_dir, filename, section_name)

        self.iterate(_save_configuration, verbose=False)

############################################################
#                      Read CSV file(s)                    #
############################################################
def missing_fields_in_csv(csv_fields, fields):

    missing = list(filter(lambda field: not (field in csv_fields),
                          fields))
    return missing

def CSV2data(csv_dir, csv_filebasename):
    print('Reading CSV file... ', end="")

    csv_filename = csv_dir + csv_filebasename + '.csv'
    # open CSV file
    try:
        f_csv = open(csv_filename)
        csv_data = csv.reader(f_csv)
        csv_fields = next(csv_data)
    except UnicodeDecodeError:
        try:
            import io

            f_csv = io.open(csv_filename, encoding='utf-16')
            csv_data = csv.reader(f_csv, delimiter=';')
            csv_fields = next(csv_data)
        except Exception:
            print('\n\tCould not read CSV file:', csv_filebasename + '.csv',
                  'Unknown type of CSV file. Exiting...')
            exit(1)

    # determine CSV type
    if ((len(csv_fields) >= 2) and (csv_fields[0] == 'Name:')
        and (len(csv_fields[1]) >= 10) and (csv_fields[1][:10] == 'Data Instr')):

        for i in range(13): next(csv_data) # skip useless header
            # replace original column names with something more readable
        csv_fields = ('scan', 'time', 'elapsed', 's101', 's102', 's103',
                      's119', 's120')
        csv_type = 'scanned_data'
        data = ExperimentData(csv_type)
    else:
        csv_type = 'regular_ini'
        required_fields = ('exp_type', 'exp_id', 'exp_no')
        missing = missing_fields_in_csv(csv_fields, required_fields)
        if not missing == []:
            print("CSV file: missing identifiers: '%s' "% missing)
            print('CSV error: cannot process CSV file, aborting...')
            exit(1)

        extended_fields = ('scan', 'csv_file', 'rpm')
        missing = missing_fields_in_csv(csv_fields, required_fields)
        if missing and (len(missing) != len(extended_fields)):
            print("CSV file: missing identifiers: '%s' "% missing)
            print('CSV error: cannot process CSV file, aborting...')
            exit(1)
        else:
            csv_type = 'scan_ini'

        identifiers = {}

        data = MultipleExperimentData(csv_type)

    csv_row = namedtuple('CSVRow', csv_fields)

    for row in map(csv_row._make, csv_data):
        if csv_type in ('regular_ini', 'scan_ini'):
            module = MODMAN.find_module(row.exp_type, submodule='csv_parse')
            skip   = get_module_function('skip', module)

            if skip(row): continue
            #FFF            print('\nFields', csv_fields, row.__dict__)
            #FFF print('D', data)
            for id_name in ('exp_type', 'exp_id', 'exp_no'):
                value = getattr(row, id_name)
                if value: identifiers[id_name] = value # update if value present
            (exp_id, exp_no) = (identifiers['exp_id'], identifiers['exp_no'])
            data.append_row(row, exp_id, exp_no)
        else:
            data.appen_row(row)

    if csv_type == 'scanned_data': # remove useless columns from data structure
        data.delete('time', 'elapsed', 's101', 's119', 's120')

    f_csv.close()

    return data

############################################################
#          Transform data and save to .ini file            #
############################################################
ITERABLE_LISTS = {}

def get_iterables_list(exp_type, modman):

    def extend_iterables_list(module):
        if hasattr(module, 'OPTIONS_ITERABLE_LISTS'):
            iterables_list.extend(module.OPTIONS_ITERABLE_LISTS)
        return True

    if exp_type in ITERABLE_LISTS:
        iterables_list = ITERABLE_LISTS[exp_type]
    else:
        iterables_list = []

        modman.traverse_ancestors(exp_type, extend_iterables_list,
                                  submodule='options')

        ITERABLE_LISTS[exp_type] = iterables_list

    return iterables_list

def data2iniV1(data, output_dir, collect_fn=None):
def data2ini(data, experiment_info):

    def _get_measurement_length(key, value, array_info):
        if ((not type(value) in [list, tuple])
            or ((not key in array_info['iterables'])
                and (not key in array_info['measurements_names']))):
            return

        if array_info['len'] == -1:
            array_info['len'] = len(value)
            array_info['ref'] = key
        elif array_info['len'] != len(value):
            print("Option list '{}' has length: {:d}\n"
                  "Reference list '{}' has length: {:d}\n:"
                  "Cannot iterate over lists of unequal length. "
                  "Aborting.".format(key, len(value),
                                     array_info['ref'], array_info['len']))
            exit(1)

    def _filter_data(key, value):
        cvalue = compress_seq(value)

        # durations need to be handled specially
        if key in ('duration', 'fh_duration', 'deceleration_duration'):
            if ((not type(cvalue) in (list, tuple))
                and float(cvalue) == 0.0):

                return 0.0
            else: return value

        if cvalue in [None, '']: return None
        else: return cvalue

    def _pre_process_data(lname, lvalue, experiment_info):
        if lname == 'exp_id':
             print("\tProcessing experiment(s) with ID: ", repr(lvalue))
        else:
            print("\t\tProcessing experiment number: ", lvalue, end="")

    def _post_process_data(lname, lvalue, experiment_info):

        if lname == 'exp_id':
            print("\tCreating default inifile for ID ",
                  repr(experiment_info['exp_id']), end = '')

            exp_base_path = get_directories('ini', 'exp_base', experiment_info)

            if path.exists(exp_base_path + DEFAULTS_ININAME):
                print('\n\t\tFile exists.\t\t\t\t\tSkipping'
                      .format(DEFAULTS_ININAME))

            else:
                default_configuration = \
                  ExperimentData({'exp_type': repr(experiment_info['exp_id'])})

                default_configuration.save(exp_base_path,
                                           filename=DEFAULTS_ININAME,
                                           section_name='experiment')

            experiment_info['exp_type'] = None # reset exp_id for _process_data

            print()

    def _process_data(experiment, experiment_info):
        # Process single configuration file
        experiment.on_modify(_filter_data) # 'None' value returned from
                                           # _filter_data() is deleted

        exp_type = experiment.get_value('exp_type')
        if type(exp_type) in (list, tuple):
            print("Experiment type 'exp_type' must be the "
                  "same for given experiment. Exiting...")
            exit(1)

        if experiment_info['exp_type'] is None:
             experiment_info['exp_type'] = exp_type
        elif experiment_info['exp_type'] != exp_type:
            print("Experiment type 'exp_type' must be the same "
                      "for all experiments with given 'exp_id'.")
            exit(1)

        experiment_info['exp_id'] = experiment.get_value('exp_id')
        experiment_info['exp_no'] = experiment.get_value('exp_no')

        (data_dir, masks_dir)  = \
          get_directories('ini', ['data', 'masks'], experiment_info)

        if not path.exists(masks_dir):
            makedirs(masks_dir) # create empty masks directory

        # determine the size of iterable items (has to be the same for all)
        array_info = {'len': -1, 'ref': None,
                      'iterables': get_iterables_list(exp_type, MODMAN),
                      'measurements_names': MEASUREMENTS_NAMES.values()}
        experiment.iterate(_get_measurement_length, user_data=array_info)
        experiment.set_value('measurements_length', max(array_info['len'], 1))


        experiment.delete('exp_id', 'exp_no', 'exp_type')

        experiment.save(data_dir, filename='measurements.ini',
                        section_name='experiment-data')

        print('\t\tDone')

    print('\nCreating data inifiles...')
    experiment_info.update(dict.fromkeys(('exp_id', 'exp_no', 'mask',
                                          'exp_type')))
    data.iterate(_process_data, user_data=experiment_info,
                 levels_names=['exp_id', 'exp_no'],
                 level_prehook=_pre_process_data,
                 level_posthook=_post_process_data)
    print('All done.')

def data2iniV2(data, output_dir, filename):
    if (len(filename) > 3) and (not filename[-4:] in ('.csv', '.ini')):
        if filename[-4:] == '.csv':
            filename[-3:] = 'ini'
        inifilename = filename
    else:
        inifilename = filename + '.ini'

    data.save(output_dir, filename, section_name='experiment-data')

if __name__ == "__main__":
    options = parse_input()
    info = {'csv_filepath': options.csv_filepath,
            'csv_filename': options.csv_filename,
            'ini_dir': INI_DIR}

    data = CSV2data(info)
    data2ini(data, info)
