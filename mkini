#!/usr/bin/python
import csv

from os import makedirs, path, sep
from optparse import OptionParser
from config import ModulesManager
from const import CSV_DIR, INI_DIR, DEFAULTS_ININAME
from shared import get_directories

REQUIRED_FIELDS = ('exp_type', 'id', 'exp_no', 'tube_no')

modman = ModulesManager()

base_module = modman.find_module('base', submodule='csv_parse')

def parse_input():

    usage_str = (
         '\n\t%prog <csv_ID>'
         '\n\nwhere'
         '\n  csv_ID:'
         '\n        ID of the csv file. By default will be searched for '
         '\n        the file ''./sources/csv/<csv_ID>[.cvs]'' ')

    optparser = OptionParser(usage=usage_str)
    optparser.add_option('-l', '--list', dest='list', action="store_true",
                         default=False,
                         help="Lists all available CSV files")

    (options, args) = optparser.parse_args()

    len_args = len(args)

    if len_args == 0:
        if options.list:
            from os import listdir

            print('\n'.join(sorted(listdir(CSV_DIR))))
        else:
            optparser.print_help()
        exit(0)

    csv_filename = CSV_DIR + sep + args[0]

    if path.exists(csv_filename):
            options.csv_filename = csv_filename
    elif  path.exists(csv_filename + '.csv'):
        options.csv_filename = csv_filename + '.csv'
    else:
        print('CSV file does not exist:{}'.format(csv_filename))
        exit(1)

    if not path.exists(INI_DIR):
        makedirs(INI_DIR)

    return options

def get_module_function(function_name, module, base_module=base_module):
    if hasattr(module, function_name):
        function = getattr(module, function_name)
    else:
        function = getattr(base_module, function_name)

    return function

def assert_csv_has_required_fields(csv_fields, required_fields):

    missing = list(filter(lambda field: not (field in csv_fields),
                          required_fields))
    if missing:
        print("CSV file: missing identifiers: '%s' "% missing)
        print('CSV error: cannot process CSV file, aborting...')
        exit(1)


def mk_data_fields(data, experiment_id, experiment_no, tube_number, fields):
    if not experiment_id in data:
        data[experiment_id]={}

    if not experiment_no in data[experiment_id]:
        data[experiment_id][experiment_no]={}

    if not tube_number in data[experiment_id][experiment_no]:
        data[experiment_id][experiment_no][tube_number]  = \
          {field: [] for field in fields}

def store_CSV_row(data, exp_type, row, indexes, csv_fields):

    experiment_id = row[indexes['id']]
    experiment_no = row[indexes['exp_no']]
    tube_number   = row[indexes['tube_no']]
    exp_type      = row[indexes['exp_type']]

    mk_data_fields(data, experiment_id, experiment_no, tube_number, csv_fields)

    experiment_data = data[experiment_id][experiment_no][tube_number]
    for (descriptor, value) in zip(csv_fields, row):
        experiment_data[descriptor].append(value)

def CSV2data(csv_filename):

    f_csv = open(csv_filename)
    csv_data = csv.reader(f_csv)

    print('Reading CSV file... ', end="")

    csv_fields = next(csv_data)

    indexes = {field: csv_fields.index(field) for field in csv_fields}

    assert_csv_has_required_fields(csv_fields, REQUIRED_FIELDS)

    exp_type_idx = indexes['exp_type']

    data = {}

    for row in csv_data:
        experiment_type = row[exp_type_idx]

        module = modman.find_module(experiment_type, submodule='csv_parse')

        skip         = get_module_function('skip', module)

        if not skip(experiment_type, row, indexes):
            store_CSV_row(data, experiment_type, row, indexes, csv_fields)

    f_csv.close()

    print('Done.')

    return data

def compress_seq(seq):
    same_value = True
    ref = seq[0]

    if not list(filter(lambda value: not (value == ref), seq)):
        return (True, ref)

    nonempty = list(filter(lambda value: not (value == ''), seq))
    items_count = len(nonempty)
    if items_count == 1:
        return (True, nonempty[0])
    elif items_count == len(seq):
        return (False, seq)
    else:
        raise('Either all values in sequence must be nonempty, or exactly one:'
              '\n {}', seq)

def save_configuration(data, savedir='', filename='', section_name=''):

    if not path.exists(savedir):
        makedirs(savedir)

    fout = open(savedir + filename, mode='w', encoding='utf-8')
    fout.write('[{}]\n'.format(section_name))

    for (descriptor, value) in data.items():
        if type(value) == list:
            (flag, cvalue) = compress_seq(value)
            if flag:
                value_str = cvalue
            else:
                value_str = '[' + (', '.join(cvalue)) +  ']'
        else:
            value_str = value

        fout.write('{:8} = {}\n'.format(descriptor, value_str))

    fout.close()

def get_noniterable_list(exp_type, modman):
    noniterable_list = []

    def extend_noniterables_list(module):
        if hasattr(module, 'NONITERABLE_LIST_OPTIONS'):
            noniterable_list.extend(module.NONITERABLE_LIST_OPTIONS)
        return True

    modman.traverse_ancestors(exp_type, extend_noniterables_list,
                              submodule='options')

    return noniterable_list

def data2ini(data, output_dir):

    print('\nCreating data inifiles...')

    for (exp_id, exp_id_struct) in data.items():
        print("\tProcessing experiment(s) with ID: ", repr(exp_id))

        id_exp_type = []

        for (exp_no, exp_no_struct) in exp_id_struct.items():
            print("\t\tProcessing experiment number: ", repr(exp_no), end="")

            for (tube_no, exp_data) in exp_no_struct.items():

                (flag, cvalue) = compress_seq(exp_data['exp_type'])
                if not flag:
                    raise ValueError("Experiment type 'exp_type' must be the "
                                     "same for given experiment. Exiting...")
                id_exp_type.append(cvalue)

                # Remove identificators
                for field in REQUIRED_FIELDS:
                    del exp_data[field]

                (data_dir, masks_dir)  = \
                  get_directories(['data', 'masks'], exp_id, exp_no, tube_no)

                save_configuration(exp_data, savedir=data_dir,
                                   filename='measurements.ini',
                                   section_name='experiment-data')

                if not path.exists(masks_dir):
                    makedirs(masks_dir) # create empty masks directory

            print('\t\tDone')

        print("\tCreating default inifile for ID ", repr(exp_id),
              end = '')
        exp_base_path = get_directories('exp_base', exp_id, None, None)

        if path.exists(exp_base_path + DEFAULTS_ININAME):
            print('\n\t\tFile exists.\t\t\t\tSkipping'
                  .format(DEFAULTS_ININAME))
        else:
            (flag, cvalue) = compress_seq(id_exp_type)
            if not flag:
                raise ValueError("Experiment type 'exp_type' must be the same "
                                 "for all experiments with given 'exp_id'.")

            save_configuration({'exp_type': repr(cvalue)},
                               savedir=exp_base_path, filename=DEFAULTS_ININAME,
                               section_name='experiment')
            print('\tDone')

    print('All done.')

if __name__ == "__main__":
    options = parse_input()
    data    = CSV2data(options.csv_filename)

    data2ini(data, INI_DIR)
