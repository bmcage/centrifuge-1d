#!/usr/bin/python
import csv

from os import makedirs, path, sep
from optparse import OptionParser
from config import ModulesManager
from const import CSV_DIR, INI_DIR, DEFAULTS_ININAME, MEASUREMENTS_NAMES
from shared import get_directories
from collections import namedtuple, defaultdict

MODMAN = ModulesManager()
REQUIRED_FIELDS = ('exp_type', 'id', 'exp_no')

BASE_MODULE = MODMAN.find_module('base', submodule='csv_parse')

# dynamicall created options: options added to generated measurements.ini
# file, that are not specified by the csv file
# {opt_name: gen_data_function} with 'gen_data_function(exp_type, data, modman)'
DYNAMIC_OPTIONS = {'measurements_length': None}

def parse_input():

    usage_str = (
         '\n\t%prog <csv_ID>'
         '\n\nwhere'
         '\n  csv_ID:'
         '\n        ID of the csv file. By default will be searched for '
         '\n        the file ''./sources/csv/<csv_ID>[.cvs]'' ')

    optparser = OptionParser(usage=usage_str)
    optparser.add_option('-l', '--list', dest='list', action="store_true",
                         default=False,
                         help="Lists all available CSV files")

    (options, args) = optparser.parse_args()

    len_args = len(args)

    if len_args == 0:
        if options.list:
            from os import listdir

            print('\n'.join(sorted(listdir(CSV_DIR))))
        else:
            optparser.print_help()
        exit(0)

    csv_filename = CSV_DIR + sep + args[0]

    if path.isdir(csv_filename):
        csv_filename += sep + args[0] + '.csv'

    if path.exists(csv_filename):
        options.csv_filename = csv_filename
    elif path.exists(csv_filename + '.csv'):
        options.csv_filename = csv_filename + '.csv'
    else:
        print('CSV file does not exist:{}'.format(csv_filename))
        exit(1)

    if not path.exists(INI_DIR):
        makedirs(INI_DIR)

    return options

def get_module_function(function_name, module, base_module=BASE_MODULE):
    if hasattr(module, function_name):
        function = getattr(module, function_name)
    else:
        function = getattr(base_module, function_name)

    return function

def compress_seq(seq):
    if not type(seq) in [list, tuple]: return seq

    ref = seq[0]

    # all(seq[:] == ref)
    if not list(filter(lambda value: not (value == ref), seq)):
        return ref

    # all are == '' except one
    nonempty = list(filter(lambda value: not (value == ''), seq))
    items_count = len(nonempty)
    if items_count == 1:
        return nonempty[0]
    elif items_count == len(seq):
        return seq
    else:
        raise('Either all values in sequence must be nonempty, or exactly one:'
              '\n {}', seq)

############################################################
#          Storage class for data read from CSV file       #
############################################################
class ExperimentData():
    def __init__(self, initial_data={}):
        self._data = defaultdict(list, initial_data)

    def get_value(self, key, not_found=None):
        if not key in self._data:
            return not_found
        else:
            return self._data[key]

    def set_value(self, key, value):
        self._data[key] = value

    def append_row(self, row):
        data = self._data

        for (key, value) in vars(row).items():
            data[key].append(value)

    def iterate(self, fn, user_data=None):
        if user_data is None:
            for (key, value) in self._data.items(): fn(key, value)
        else:
            for (key, value) in self._data.items(): fn(key, value, user_data)

    def delete(self, *keys):
        data = self._data
        for key in keys: del data[key]

    def on_modify(self, fn):
        """
        Set the value returned by function fn as new value. If new_value is
        'None', then the key is deleted. Type of fn: fn(key, value)->new_value
        """

        delete_items = []

        experiment_data = self._data

        for (key, value) in experiment_data.items():
            new_value = fn(key, value)
            if new_value is None: delete_items.append(key)
            else: experiment_data[key] = new_value

        self.delete(*delete_items)

    def save(self, save_dir, filename=DEFAULTS_ININAME,
             section_name='experiment'):

        def _princ(key, value, stream):
            if type(value) in (list, tuple):
                value_str = '[' + (', '.join(value)) +  ']'
            else:
                value_str = value

            stream.write('{:8} = {}\n'.format(key, value_str))

        if callable(save_dir):
            savedir = save_dir(self)
        else:
            savedir = save_dir

        if not path.exists(savedir):
            makedirs(savedir)

        fout = open(savedir + filename, mode='w', encoding='utf-8')
        fout.write('[{}]\n'.format(section_name))

        self.iterate(_princ, user_data=fout)

        fout.close()

class MultipleExperimentData():
    def __init__(self):
        self._data = {}

    def pick(self):
        leaf = self._data

        while not isinstance(leaf, ExperimentData):
            leaf = leaf.keys()[0]

        return leaf

    def _get_leaf(self, ids, create_p=False, not_found=None):
        data          = self._data
        parental_data = None

        for identifier in ids:
            if not identifier in data:
                if create_p:
                    data[identifier] = {}
                else:
                    return not_found
            parental_data = data
            data = data[identifier]

        if data == {}:
            data = ExperimentData()
            print('ids', ids)
            parental_data[ids[-1]] = data
            #FFF print('\nDDD', data, ids)
        return data

    def get_value(self, key, not_found=None, *ids):
        leaf = self._get_leaf(ids, not_found=EOFError)
        if leaf == EOFError:
            return not_found
        else:
            return leaf.get_value(key)

    def set_value(self, key, value, *ids):
        leaf = self._get_leaf(ids, create_p=True)
        leaf.set_value(key, value)

    def append_row(self, row, *ids):
        leaf = self._get_leaf(ids, create_p=True)
        #FFF print('\nLeaf', leaf)
        leaf.append_row(row)

    def iterate(self, fn, user_data=None, level_prehook=None,
                level_posthook=None, levels_names=None):

        def _traverse(struct, level):
            if isinstance(struct, ExperimentData):
                if user_data is None:
                    fn(struct)
                else:
                    fn(struct, user_data)
            else:
                for (key, value) in struct.items():
                    if not level_prehook is None:
                        if levels_names:
                            if not user_data is None:
                                level_prehook(levels_names[level], key,
                                              user_data)
                            else:
                                level_prehook(levels_names[level], key)

                        else:
                            level_prehook(key, user_data)

                    _traverse(value, level+1)

                    if not level_posthook is None:
                        if levels_names:
                            if not user_data is None:
                                level_posthook(levels_names[level], key,
                                               user_data)
                            else:
                                level_posthook(levels_names[level], key)

                        else:
                            level_posthook(key, user_data)

        _traverse(self._data, 0)

    def delete(self, *keys):
        def _delete_on_leafs(experiment):
            experiment.delete(*keys)

        self.iterate(_delete_on_leafs)

    def on_modify(self, fn):
        def _modify_leafs(experiment):
            experiment.on_modify(fn)

        self.iterate(_modify_leafs)

    def save(self, save_dir, filename=DEFAULTS_ININAME,
             section_name='experiment'):

        def _save_configuration(experiment):
            experiment.save(save_dir, filename, section_name)

        self.iterate(_save_configuration, verbose=False)

############################################################
#                      Read CSV file(s)                    #
############################################################
def missing_fields_in_csv(csv_fields, fields):

    missing = list(filter(lambda field: not (field in csv_fields),
                          fields))
    return missing

def CSV2data(csv_dir, csv_filename):
    print('Reading CSV file... ', end="")

    # open CSV file
    try:
        f_csv = open(csv_filename)
        csv_data = csv.reader(f_csv)
        csv_fields = next(csv_data)
    except UnicodeDecodeError:
        try:
            import io

            f_csv = io.open(csv_filename, encoding='utf-16')
            csv_data = csv.reader(f_csv, delimiter=';')
            csv_fields = next(csv_data)
        except Exception:
            print('\n\tCould not read CSV file:', csv_filename,
                  'Unknown type of CSV file. Exiting...')
            exit(1)

    # determine CSV type
    if ((len(csv_fields) >= 2) and (csv_fields[0] == 'Name:')
        and (len(csv_fields[1]) >= 10) and (csv_fields[1][:10] == 'Data Instr')):

        for i in range(13): next(csv_data) # skip useless header
            # replace original column names with something more readable
        csv_fields = ('scan', 'time', 'elapsed', 's101', 's102', 's103',
                      's119', 's120')
        csv_type = 2
        data = ExperimentData()
    else:
        csv_type = 1
        required_fields = ('exp_type', 'id', 'exp_no')
        missing = missing_fields_in_csv(csv_fields, required_fields)
        if not missing == []:
            print("CSV file: missing identifiers: '%s' "% missing)
            print('CSV error: cannot process CSV file, aborting...')
            exit(1)

        extended_fields = ('scan', 'csv_file', 'rpm')
        missing = missing_fields_in_csv(csv_fields, required_fields)
        if missing and (len(missing) != len(extended_fields)):
            print("CSV file: missing identifiers: '%s' "% missing)
            print('CSV error: cannot process CSV file, aborting...')
            exit(1)

        identifiers = {}

        data = MultipleExperimentData()

    csv_row = namedtuple('CSVRow', csv_fields)

    for row in map(csv_row._make, csv_data):
        if csv_type == 1:
            module = MODMAN.find_module(row.exp_type, submodule='csv_parse')
            skip   = get_module_function('skip', module)

            if skip(row): continue
            #FFF            print('\nFields', csv_fields, row.__dict__)
            #FFF print('D', data)
            for id_name in ('exp_type', 'id', 'exp_no'):
                value = getattr(row, id_name)
                if value: identifiers[id_name] = value # update if value present
            (exp_id, exp_no) = (identifiers['id'], identifiers['exp_no'])
            data.append_row(row, exp_id, exp_no)
        else:
            data.appen_row(row)

    if csv_type == 2: # remove useless columns from data structure
        data.delete('time', 'elapsed', 's101', 's119', 's120')

    f_csv.close()

    return data

ITERABLE_LISTS = {}

def get_iterables_list(exp_type, modman):

    def extend_iterables_list(module):
        if hasattr(module, 'OPTIONS_ITERABLE_LISTS'):
            iterables_list.extend(module.OPTIONS_ITERABLE_LISTS)
        return True

    if exp_type in ITERABLE_LISTS:
        iterables_list = ITERABLE_LISTS[exp_type]
    else:
        iterables_list = []

        modman.traverse_ancestors(exp_type, extend_iterables_list,
                                  submodule='options')
def get_measurements_array_length(exp_type, data, modman):
    iterables = get_iterables_list(exp_type, modman)
    measurements_names = MEASUREMENTS_NAMES.values()

        ITERABLE_LISTS[exp_type] = iterables_list
    measurements_list_length = -1
    ref_key = None

    return iterables_list
    for (key, value) in data.items():
        if ((not type(value) in [list, tuple])
            or ((not key in iterables) and (not key in measurements_names))):
            continue

        if measurements_list_length == -1:
            ref_key = key
            measurements_list_length = len(value)
            continue

        if len(value) != measurements_list_length:
            print("Option list '{}' has length: {:d}\n"
                  "Reference list '{}' has length: {:d}\n:"
                  "Cannot iterate over lists of unequal length. "
                  "Aborting.".format(key, len(value), ref_key, iterations))
    return max(measurements_list_length, 1)

DYNAMIC_OPTIONS['measurements_length'] = get_measurements_array_length

def data2ini(data, output_dir):

    def _filter_data(experiment_data):
        empty_items = []

        for (descriptor, value) in experiment_data.items():
            cvalue = compress_seq(value)
            if cvalue in [None, '']: empty_items.append(descriptor)
            else: experiment_data[descriptor] = cvalue

        for descriptor in empty_items: del experiment_data[descriptor]

        return experiment_data

    print('\nCreating data inifiles...')

    for (exp_id, exp_id_struct) in data.items():
        print("\tProcessing experiment(s) with ID: ", repr(exp_id))

        id_exp_type = []

        for (exp_no, exp_data) in exp_id_struct.items():
            print("\t\tProcessing experiment number: ", exp_no, end="")

            compr_exp_type = compress_seq(exp_data['exp_type'])
            if type(compr_exp_type) in (list, tuple):
                print('I', compr_exp_type)
                print("Experiment type 'exp_type' must be the "
                      "same for given experiment. Exiting...")
                exit(1)
            id_exp_type.append(compr_exp_type)

            # Remove identificators
            for field in REQUIRED_FIELDS:
                del exp_data[field]

            experiment_info =  {'exp_id': exp_id, 'exp_no': exp_no, 'mask': None}

            (data_dir, masks_dir)  = \
              get_directories('ini', ['data', 'masks'], experiment_info)

            for (name, dyndata_fn) in DYNAMIC_OPTIONS.items():
                exp_data[name] = dyndata_fn(compr_exp_type, exp_data, modman)

            save_configuration(_filter_data(exp_data), savedir=data_dir,
                               filename='measurements.ini',
                               section_name='experiment-data')

            if not path.exists(masks_dir):
                makedirs(masks_dir) # create empty masks directory

            print('\t\tDone')

        print("\tCreating default inifile for ID ", repr(exp_id),
              end = '')

        exp_base_path = get_directories('ini', 'exp_base', experiment_info)

        if path.exists(exp_base_path + DEFAULTS_ININAME):
            print('\n\t\tFile exists.\t\t\t\t\tSkipping'
                  .format(DEFAULTS_ININAME))
        else:
            cvalue = compress_seq(id_exp_type)
            if type(cvalue) in (list, tuple):
                print("Experiment type 'exp_type' must be the same "
                      "for all experiments with given 'exp_id'.")
                exit(1)

            save_configuration({'exp_type': repr(cvalue)},
                               savedir=exp_base_path, filename=DEFAULTS_ININAME,
                               section_name='experiment')
            print('\tDone')

    print('All done.')

if __name__ == "__main__":
    options = parse_input()
    data    = CSV2data(options.csv_filename)

    data2ini(data, INI_DIR)
