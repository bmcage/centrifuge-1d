#!/usr/bin/python
import csv

from os import makedirs, path, sep
from optparse import OptionParser
from config import ModulesManager
from const import CSV_DIR, INI_DIR, DEFAULTS_ININAME, MEASUREMENTS_NAMES
from shared import get_directories

REQUIRED_FIELDS = ('exp_type', 'id', 'exp_no')

modman = ModulesManager()

base_module = modman.find_module('base', submodule='csv_parse')

# dynamicall created options: options added to generated measurements.ini
# file, that are not specified by the csv file
# {opt_name: gen_data_function} with 'gen_data_function(exp_type, data, modman)'
DYNAMIC_OPTIONS = {'measurements_length': None}

def parse_input():

    usage_str = (
         '\n\t%prog <csv_ID>'
         '\n\nwhere'
         '\n  csv_ID:'
         '\n        ID of the csv file. By default will be searched for '
         '\n        the file ''./sources/csv/<csv_ID>[.cvs]'' ')

    optparser = OptionParser(usage=usage_str)
    optparser.add_option('-l', '--list', dest='list', action="store_true",
                         default=False,
                         help="Lists all available CSV files")

    (options, args) = optparser.parse_args()

    len_args = len(args)

    if len_args == 0:
        if options.list:
            from os import listdir

            print('\n'.join(sorted(listdir(CSV_DIR))))
        else:
            optparser.print_help()
        exit(0)

    csv_filename = CSV_DIR + sep + args[0]

    if path.exists(csv_filename):
            options.csv_filename = csv_filename
    elif  path.exists(csv_filename + '.csv'):
        options.csv_filename = csv_filename + '.csv'
    else:
        print('CSV file does not exist:{}'.format(csv_filename))
        exit(1)

    if not path.exists(INI_DIR):
        makedirs(INI_DIR)

    return options

def get_module_function(function_name, module, base_module=base_module):
    if hasattr(module, function_name):
        function = getattr(module, function_name)
    else:
        function = getattr(base_module, function_name)

    return function

def assert_csv_has_required_fields(csv_fields, required_fields):

    missing = list(filter(lambda field: not (field in csv_fields),
                          required_fields))
    if missing:
        print("CSV file: missing identifiers: '%s' "% missing)
        print('CSV error: cannot process CSV file, aborting...')
        exit(1)

def CSV2data(csv_filename):

    def _mk_empty_fields(data, experiment_id, experiment_no, fields):
        if not experiment_id in data:
            data[experiment_id]={}

        if not experiment_no in data[experiment_id]:
            data[experiment_id][experiment_no] = \
              {field: [] for field in fields}

    identifiers = {}

    def _store_CSV_row(data, exp_type, row, indexes, csv_fields):
        nonlocal identifiers

        for id_name in ('exp_type', 'id', 'exp_no'):
            if row[indexes[id_name]]: identifiers[id_name] = row[indexes[id_name]]

        _mk_empty_fields(data, identifiers['id'], identifiers['exp_no'],
                         csv_fields)

        experiment_data = data[identifiers['id']][identifiers['exp_no']]
        for (descriptor, value) in zip(csv_fields, row):
            experiment_data[descriptor].append(value)

    # Function body
    f_csv = open(csv_filename)
    csv_data = csv.reader(f_csv)

    print('Reading CSV file... ', end="")

    csv_fields = next(csv_data)

    indexes = {field: csv_fields.index(field) for field in csv_fields}

    assert_csv_has_required_fields(csv_fields, REQUIRED_FIELDS)

    exp_type_idx = indexes['exp_type']

    data = {}

    for row in csv_data:
        experiment_type = row[exp_type_idx]

        module = modman.find_module(experiment_type, submodule='csv_parse')

        skip         = get_module_function('skip', module)

        if not skip(experiment_type, row, indexes):
            _store_CSV_row(data, experiment_type, row, indexes, csv_fields)

    f_csv.close()

    print('Done.')

    return data

def compress_seq(seq):
    same_value = True
    ref = seq[0]

    if not list(filter(lambda value: not (value == ref), seq)):
        return (True, ref)

    nonempty = list(filter(lambda value: not (value == ''), seq))
    items_count = len(nonempty)
    if items_count == 1:
        return (True, nonempty[0])
    elif items_count == len(seq):
        return (False, seq)
    else:
        raise('Either all values in sequence must be nonempty, or exactly one:'
              '\n {}', seq)

def save_configuration(data, savedir='', filename='', section_name=''):

    if not path.exists(savedir):
        makedirs(savedir)

    fout = open(savedir + filename, mode='w', encoding='utf-8')
    fout.write('[{}]\n'.format(section_name))

    for (descriptor, value) in data.items():
        if type(value) == list:
            (flag, cvalue) = compress_seq(value)
            if flag:
                value_str = cvalue
            else:
                value_str = '[' + (', '.join(cvalue)) +  ']'
        else:
            value_str = value

        fout.write('{:8} = {}\n'.format(descriptor, value_str))

    fout.close()

def get_iterables_list(exp_type, modman):
    iterables_list = []

    def extend_iterables_list(module):
        if hasattr(module, 'OPTIONS_ITERABLE_LIST'):
            noniterable_list.extend(module.OPTIONS_ITERABLE_LIST)
        return True

    modman.traverse_ancestors(exp_type, extend_iterables_list,
                              submodule='options')

    return iterables_list

def get_measurements_array_length(exp_type, data, modman):
    iterables = get_iterables_list(exp_type, modman)
    measurements_names = MEASUREMENTS_NAMES.values()

    measurements_list_length = -1
    ref_key = None

    for (key, value) in data.items():
        if ((not type(value) in [list, tuple])
            or ((not key in iterables) and (not key in measurements_names))):
            continue

        if measurements_list_length == -1:
            ref_key = key
            measurements_list_length = len(value)
            continue

        if len(value) != measurements_list_length:
            print("Option list '{}' has length: {:d}\n"
                  "Reference list '{}' has length: {:d}\n:"
                  "Cannot iterate over lists of unequal length. "
                  "Aborting.".format(key, len(value), ref_key, iterations))
    return max(measurements_list_length, 1)

DYNAMIC_OPTIONS['measurements_length'] = get_measurements_array_length

def data2ini(data, output_dir):

    print('\nCreating data inifiles...')

    for (exp_id, exp_id_struct) in data.items():
        print("\tProcessing experiment(s) with ID: ", repr(exp_id))

        id_exp_type = []

        for (exp_no, exp_data) in exp_id_struct.items():
            print("\t\tProcessing experiment number: ", repr(exp_no), end="")

            (flag, compr_exp_type) = compress_seq(exp_data['exp_type'])
            if not flag:
                raise ValueError("Experiment type 'exp_type' must be the "
                                 "same for given experiment. Exiting...")
            id_exp_type.append(compr_exp_type)

            # Remove identificators
            for field in REQUIRED_FIELDS:
                del exp_data[field]

            experiment_info =  {'exp_id': exp_id, 'exp_no': exp_no, 'mask': None}

            (data_dir, masks_dir)  = \
              get_directories('ini', ['data', 'masks'], experiment_info)

            for (name, dyndata_fn) in DYNAMIC_OPTIONS.items():
                exp_data[name] = dyndata_fn(compr_exp_type, exp_data, modman)

            save_configuration(exp_data, savedir=data_dir,
                               filename='measurements.ini',
                               section_name='experiment-data')

            if not path.exists(masks_dir):
                makedirs(masks_dir) # create empty masks directory

            print('\t\tDone')

        print("\tCreating default inifile for ID ", repr(exp_id),
              end = '')

        exp_base_path = get_directories('ini', 'exp_base', experiment_info)

        if path.exists(exp_base_path + DEFAULTS_ININAME):
            print('\n\t\tFile exists.\t\t\t\tSkipping'
                  .format(DEFAULTS_ININAME))
        else:
            (flag, cvalue) = compress_seq(id_exp_type)
            if not flag:
                raise ValueError("Experiment type 'exp_type' must be the same "
                                 "for all experiments with given 'exp_id'.")

            save_configuration({'exp_type': repr(cvalue)},
                               savedir=exp_base_path, filename=DEFAULTS_ININAME,
                               section_name='experiment')
            print('\tDone')

    print('All done.')

if __name__ == "__main__":
    options = parse_input()
    data    = CSV2data(options.csv_filename)

    data2ini(data, INI_DIR)
